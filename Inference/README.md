# Tomato Detection Inference File
Tomato Detection using YoloV4 Models (running in onnxruntime). This model will detect tomato and count it from input images. The model will return dictionary results of prediction model.

# Installation

Clone the repository
```bash
git clone https://github.com/Clayrisee/TomatoDetection.git
```
Go to inference directory and run init_project.sh script
```bash
cd Inference
sh init_project.sh
```

Walaa~, you can detect the tomato.

# Directory Structure
```bash
â”œâ”€â”€ init_project.sh # script for initialize project
â”œâ”€â”€ main.py # main script for inference
â”œâ”€â”€ model
â”‚Â Â  â””â”€â”€ yolov4_1_3_416_416_static.onnx # model
â”œâ”€â”€ modul # our custom package for yolov4 inference
â”‚Â Â  â”œâ”€â”€ stereo_vision # Stereo vision package for run yolov4 in stereo camera
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ calibrate_camera.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ calibration.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ images
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ stereoLeft
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ imageL0.png
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ imageL1.png
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ imageL2.png
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ imageL3.png
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ imageL4.png
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ imageL5.png
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ stereoRight
â”‚Â Â  â”‚Â Â  â”‚Â Â      â”œâ”€â”€ imageR0.png
â”‚Â Â  â”‚Â Â  â”‚Â Â      â”œâ”€â”€ imageR1.png
â”‚Â Â  â”‚Â Â  â”‚Â Â      â”œâ”€â”€ imageR2.png
â”‚Â Â  â”‚Â Â  â”‚Â Â      â”œâ”€â”€ imageR3.png
â”‚Â Â  â”‚Â Â  â”‚Â Â      â”œâ”€â”€ imageR4.png
â”‚Â Â  â”‚Â Â  â”‚Â Â      â””â”€â”€ imageR5.png
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ stereo_calibration.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ stereoMap.xml
â”‚Â Â  â””â”€â”€ tomato_detection # main modul for detection.
â”‚Â Â      â”œâ”€â”€ __init__.py
â”‚Â Â      â”œâ”€â”€ tomato_maturity_level.py
â”‚Â Â      â”œâ”€â”€ TomatoModel.py
â”‚Â Â      â””â”€â”€ tools.py
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ test_image
    â”œâ”€â”€ sample_left.jpeg
    â”œâ”€â”€ sample_right.jpeg
    â”œâ”€â”€ test_image_2.jpg
    â””â”€â”€ test_image.jpg

```


# How to use
If you only want to use TomatoModel for detect object you can follow the example bellow.

## Initialization argument
```python
class TomatoModel:
    def __init__(self, onnx_path="model/yolov4_1_3_416_416_static.onnx", threshold=0.5 ,input_size=(416, 416)):
        """
        Parameters:
        ----------
        onnx_path: str
                Path onnx weights
        threshold: float
                Threshold for set minimum confidence of the model
        input_size: tuple
                Input Image Size
        """
```
## Output Format
```python
{
    "tomato_count": int,
    "results": [
        {
            "bounding_boxes": "{Return Tupple of Coordinates Prediction}",
            "label":"tomato",
            "confidence": "{Accuracy prediction model}"
        }
    ]
}
```
## Example
```python
from modul.tomato_detection.TomatoModel import TomatoModel
import cv2

model = TomatoModel(onnx_path="model/yolov4_1_3_416_416_static.onnx") # Load onnx model
img = cv2.imread("test_image/test_image_2.jpg", 1) # Input image
results = model.predict(img)
print(results)
# OUTPUT:
# {'tomato_count': 4, 'results': [{'bounding_box': (20, 301, 192, 411), 'label': 'tomato', 'confidence': 0.99486065}, {'bounding_box': (10, 109, 196, 235), 'label': 'tomato', 'confidence': 0.9945724}, {'bounding_box': (0, 0, 182, 84), 'label': 'tomato', 'confidence': 0.9843072}, {'bounding_box': (43, 205, 220, 300), 'label': 'tomato', 'confidence': 0.89212906}]}
```


# Feedback

If you have any feedback, please reach out to us at linkedin
  
## ðŸ”— Contact Us
[![linkedin](https://img.shields.io/badge/linkedin-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/haikalardikatama/)

[![linkedin](https://img.shields.io/badge/linkedin-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/manfredmichael/?locale=in_ID)

Clayrisee@2021
  
